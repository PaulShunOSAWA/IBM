{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abd2f3a-7930-44bc-9a5f-3646677309bd",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \">\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b80864-134b-4e19-b978-042c3752181d",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5bdfa8-6014-495e-af4c-1905a13cf122",
   "metadata": {},
   "source": [
    "<h1><h1>Pre-trained-Models with PyTorch </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53741054-55b8-4d99-9976-6032dbb90087",
   "metadata": {},
   "source": [
    "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n",
    "<ul>\n",
    "<li>change the output layer</li>\n",
    "<li> train the model</li> \n",
    "<li>  identify  several  misclassified samples</li> \n",
    " </ul>\n",
    "You will take several screenshots of your work and share your notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c08cf-34b0-406d-8125-0593277f34bc",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f07a2-6a2d-4608-84f2-0cc62bf2501b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
    "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
    "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
    "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
    "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
    "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
    " </div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb7083-02ed-4c9c-b5b4-7b0418388a2a",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efedf9be-c643-4d62-8158-0918061c6b8b",
   "metadata": {},
   "source": [
    "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Positive_tensors.zip\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\"\n",
    "output_file = \"Positive_tensors.zip\"\n",
    "\n",
    "# ファイルをダウンロードして保存\n",
    "response = requests.get(url)\n",
    "with open(output_file, \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(f\"Downloaded {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Negative_tensors.zip\n"
     ]
    }
   ],
   "source": [
    "# ダウンロード URL と保存するファイル名\n",
    "url = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\"\n",
    "output_file = \"Negative_tensors.zip\"\n",
    "\n",
    "# Negative_tensors.zip をダウンロード\n",
    "response = requests.get(url)\n",
    "with open(output_file, \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(f\"Downloaded {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad15709-e387-40fd-ab2f-8fde44dea3e1",
   "metadata": {},
   "source": [
    "We will install torchvision:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4397a6-b3f6-4b0e-b9f9-c0e294eede06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\python312\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: pillow in c:\\python312\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: h5py in c:\\python312\\lib\\site-packages (3.12.1)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch) (70.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision pillow pandas matplotlib numpy h5py torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720b2e1a-fa06-4daf-a922-4a70777f6709",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadbf87-12b4-4cf5-973b-d074375b21f7",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "100c4913-0f97-425c-bf42-eba819ed5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c864cbda50>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pandas\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "62927ada-7de8-485c-a08e-cb2b038b25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed9c29-48b2-4bbf-9ba9-7f6fc1c088a2",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b81ceb-2ff9-4e71-b0ad-bcd507f91029",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630dc80-3ee1-40a4-84d7-0427cd7101c7",
   "metadata": {},
   "source": [
    " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4c2612bc-5ed4-4f7d-bc9d-71c6a69ce2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "# Create your own dataset object\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, transform=None, train=True):\n",
    "        directory = \"./\"\n",
    "        positive = \"Positive_tensors\"\n",
    "        negative = \"Negative_tensors\"\n",
    "\n",
    "        positive_file_path = os.path.join(directory, positive)\n",
    "        negative_file_path = os.path.join(directory, negative)\n",
    "        positive_files = [os.path.join(positive_file_path, file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
    "        negative_files = [os.path.join(negative_file_path, file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
    "        number_of_samples = len(positive_files) + len(negative_files)\n",
    "        self.all_files = [None] * number_of_samples\n",
    "        self.all_files[::2] = positive_files\n",
    "        self.all_files[1::2] = negative_files \n",
    "        self.transform = transform\n",
    "        self.Y = torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2] = 1\n",
    "        self.Y[1::2] = 0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files = self.all_files[0:30000]\n",
    "            self.Y = self.Y[0:30000]\n",
    "            self.len = len(self.all_files)\n",
    "        else:\n",
    "            self.all_files = self.all_files[30000:]\n",
    "            self.Y = self.Y[30000:]\n",
    "            self.len = len(self.all_files)     \n",
    "\n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.load(self.all_files[idx])  # テンソルとしてロード\n",
    "        y = self.Y[idx]\n",
    "        \n",
    "        # テンソルをPIL Imageに変換\n",
    "        image = ToPILImage()(image)\n",
    "        \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747173bb-89d3-45e8-b058-ab209f14610c",
   "metadata": {},
   "source": [
    "We create two dataset objects, one for the training data and one for the validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0618234d-d2a4-459a-aed0-20e3803a4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# 画像の前処理を定義\n",
    "composed = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# データセットの定義\n",
    "train_dataset = Dataset(transform=composed, train=True)\n",
    "validation_dataset = Dataset(transform=composed, train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d6186-c5e3-4594-b469-fc776d407fe5",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_1\">Question 1</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3bc6f-c9ce-4bc6-98e2-160b4c2c6be3",
   "metadata": {},
   "source": [
    "<b>Prepare a pre-trained resnet18 model :</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd3ebc-0de2-4418-9316-a20a12ec7034",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "293cde0f-d36f-4584-a1ff-d4fe736b9fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Step 1: Load the pre-trained model resnet18\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b310a4-2eb5-4627-ae5e-d0783ba838ad",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22ed14f3-ded5-47a6-b667-34e9d5bc0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f23176-eca4-4e8f-9ec2-a164a5a7ef65",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410287ff-6594-4af8-8acc-495106d31545",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4f79a8c7-4e3c-48b2-8d5c-75ec66fc7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model.fc = nn.Linear(in_features=512, out_features=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fe114-92ee-4c41-aede-1e016711ffcd",
   "metadata": {},
   "source": [
    "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1462f12b-da03-4175-ad74-043e46166410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb183bcf-8cfa-4e48-93e8-af78f42e57b0",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91768582-592a-4360-b47c-1c7db7008ff8",
   "metadata": {},
   "source": [
    "In this question you will train your, model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455f1a9-a0af-4502-9179-0a4693cf06d8",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5263c76f-483d-42bf-9716-c526278d3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f9645-a2ff-4900-91e7-4acf3eec2427",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 30000\n",
      "Number of validation samples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of validation samples:\", len(validation_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f006c789-b1d6-4eb9-bdc4-613265ac440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=15)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a965344-294c-4f35-881b-6f3b7e938149",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ffbf141-4354-429f-ba64-cf0fecf4d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f8e4c-8cc9-477a-b291-3aedf0d0852e",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f9e3b-f4a4-430d-92e4-2b204f4f9162",
   "metadata": {},
   "source": [
    "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e10db4f0-56f4-4c94-940f-133f5764ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation samples: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\大澤峻\\AppData\\Local\\Temp\\ipykernel_13772\\734675799.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(self.all_files[idx])  # テンソルとしてロード\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "correct = 0\n",
    "N_test = len(validation_dataset)\n",
    "N_train = len(train_dataset)\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Number of validation samples:\", N_test)\n",
    "\n",
    "Loss = 0\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in train_loader:\n",
    "        model.train()\n",
    "        # Clear gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Make a prediction\n",
    "        y_hat = model(x)  # フラット化せず、そのまま x を渡します\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        # Calculate gradients of parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.item())  # `.data` を `item()` に修正\n",
    "        \n",
    "    correct = 0\n",
    "    for x_test, y_test in validation_loader:\n",
    "        # Set model to eval\n",
    "        model.eval()\n",
    "        \n",
    "        # Make a prediction (フラット化せず、そのまま x_test を渡す)\n",
    "        y_hat_test = model(x_test)\n",
    "        \n",
    "        # Find max\n",
    "        _, predicted = torch.max(y_hat_test, 1)\n",
    "        \n",
    "        # Calculate correctly classified samples in mini-batch\n",
    "        correct += (predicted == y_test).sum().item()\n",
    "    \n",
    "    accuracy = correct / N_test\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "print(\"Training completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f3003-c65d-40bc-96ad-5c9c48c99f3b",
   "metadata": {},
   "source": [
    "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f321eee5-544b-4659-839f-0e6ea591d09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c7ae1d7-abbd-4e21-b0f2-9e45b967a1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1f6bc-f2ba-4b06-9109-7778966e1379",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78f947-6f88-4871-8005-d5732cd8e2d9",
   "metadata": {},
   "source": [
    "<b>Identify the first four misclassified samples using the validation data:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\大澤峻\\AppData\\Local\\Temp\\ipykernel_13772\\734675799.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(self.all_files[idx])  # テンソルとしてロード\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0 yhat tensor([0]) y tensor([1])\n",
      "sample 18 yhat tensor([0]) y tensor([1])\n",
      "sample 44 yhat tensor([0]) y tensor([1])\n",
      "sample 48 yhat tensor([0]) y tensor([1])\n"
     ]
    }
   ],
   "source": [
    "misclassified_samples = 0  # 誤分類されたサンプル数をカウント\n",
    "misclassified_results = []  # 結果を格納するリスト\n",
    "\n",
    "for i, (x_test, y_test) in enumerate(validation_loader):\n",
    "    model.eval()  # 評価モードに設定\n",
    "    y_hat_test = model(x_test)  # 予測値を取得\n",
    "    _, predicted = torch.max(y_hat_test, 1)  # 予測クラスを取得\n",
    "    \n",
    "    # 誤分類されたサンプルをチェック\n",
    "    for j in range(len(y_test)):\n",
    "        if predicted[j] != y_test[j]:\n",
    "            # 誤分類されたサンプルのインデックス、予測値、実際の値を格納\n",
    "            misclassified_results.append(f\"sample {i * len(y_test) + j} yhat {predicted[j].unsqueeze(0)} y {y_test[j].unsqueeze(0)}\")\n",
    "            misclassified_samples += 1\n",
    "        \n",
    "        # 最初の4つの誤分類サンプルのみを表示\n",
    "        if misclassified_samples >= 4:\n",
    "            break\n",
    "    if misclassified_samples >= 4:\n",
    "        break\n",
    "\n",
    "# 結果の表示\n",
    "for result in misclassified_results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b8fe6-26bd-4bb9-b8da-1ca492528ee6",
   "metadata": {},
   "source": [
    "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html?utm_source=Exinfluencer&utm_content=000026UJ&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01&utm_medium=Exinfluencer&utm_term=10006555\"> CLICK HERE </a> Click here to see how to share your notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f20a3f-7d1b-4aea-9e74-e373ec30e1bb",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb64cce-3fe5-489d-bced-79c3e7a447cf",
   "metadata": {},
   "source": [
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-21  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a379170-e56f-40f9-9f8f-e3227416419a",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">MIT License</a>.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
